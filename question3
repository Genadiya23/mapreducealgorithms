from pyspark.sql import SparkSession
from pyspark.sql.functions import col, countDistinct, desc

# Initialize a SparkSession
spark = SparkSession.builder.appName("HetIONetAnalysis").getOrCreate()

# File paths
nodes_path = "/Users/yanasivakova/Downloads/hetionet/nodes.tsv"
edges_path = "/Users/yanasivakova/Downloads/hetionet/edges.tsv"

# Load nodes and edges data
nodes_df = spark.read.option("delimiter", "\t").option("header", True).csv(nodes_path)
edges_df = spark.read.option("delimiter", "\t").option("header", True).csv(edges_path)

# Step 1: Filter edges for drug-gene associations (CuG, CdG, CbG)
drug_gene_df = edges_df.filter(col("metaedge").isin("CuG", "CdG", "CbG"))

# Step 2: Count distinct genes associated with each drug
# "source" represents the drug (compound), and "target" represents the gene
drug_gene_count = drug_gene_df.groupBy("source").agg(countDistinct("target").alias("gene_count"))

# Step 3: Ensure "gene_count" is treated as a numeric column for correct sorting
drug_gene_count = drug_gene_count.withColumn("gene_count", col("gene_count").cast("int"))

# Step 4: Join with nodes to get the drug names (assuming "source" in edges matches "id" in nodes)
drug_gene_names = drug_gene_count.join(nodes_df, drug_gene_count.source == nodes_df.id, "inner") \
    .select(nodes_df.name.alias("drug_name"), "gene_count")  # Select drug names and gene count

# Step 5: Sort by gene count in descending order
top_drugs = drug_gene_names.orderBy(desc("gene_count")).limit(5)

# Step 6: Collect results and display them in custom format
results = top_drugs.collect()

# Step 7: Print results in the desired format
print("Drug Name -> Gene Count")
for row in results:
    print(f"{row['drug_name']} -> {row['gene_count']}")
